{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF__ZzEO-B2P"
      },
      "source": [
        "## 利用HMM來實現pos演算法\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T180tu9i8D7g",
        "outputId": "d6a666c4-0bc2-4993-8e8c-f4c7cb00f550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RnZbMGZ-VmU",
        "outputId": "2403bb9b-225e-4a88-a740-7d09a1241817"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting conllu\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/be/be6959c3ff2dbfdd87de4be0ccdff577835b5d08b1d25bf7fd4aaf0d7add/conllu-4.4-py2.py3-none-any.whl\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-4.4\n"
          ]
        }
      ],
      "source": [
        "!pip install conllu\n",
        "\n",
        "from io import open\n",
        "from conllu import parse_incr\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "\n",
        "data_file = open(\"/content/drive/My Drive/zh_gsd-ud-train.conllu\", \"r\", encoding=\"utf-8\")\n",
        "\n",
        "# save dataset\n",
        "sentences_list = []\n",
        "pos_list = []\n",
        "start_token = '--s--'\n",
        "\n",
        "for tokenlist in parse_incr(data_file):\n",
        "    temp_str = []\n",
        "    temp_pos = []\n",
        "    temp_str.append(start_token)\n",
        "    temp_pos.append(start_token)\n",
        "    for s in tokenlist:\n",
        "        temp_str.append(s['form'])\n",
        "        temp_pos.append(s['upos'])\n",
        "    sentences_list.append(temp_str)\n",
        "    pos_list.append(temp_pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcu-LtWh-wOf",
        "outputId": "8fe53fdc-d0f8-4ba9-80c1-d397788b48f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary dictionary, key is the word, value is a unique integer\n",
            "--s--:0\n",
            "看似:1\n",
            "簡單:2\n",
            "，:3\n",
            "只:4\n",
            "是:5\n",
            "二:6\n",
            "選:7\n",
            "一:8\n",
            "做:9\n",
            "決擇:10\n",
            "但:11\n",
            "其實:12\n",
            "他們:13\n",
            "代表:14\n",
            "的:15\n",
            "你:16\n",
            "周遭:17\n",
            "親朋:18\n",
            "好友:19\n",
            "試:20\n"
          ]
        }
      ],
      "source": [
        "# vocab: 將詞記錄在字典中\n",
        "vocab = {}\n",
        "cnt_word = 0\n",
        "\n",
        "for sentence in sentences_list: \n",
        "    for word in sentence:\n",
        "      if word not in vocab:\n",
        "        vocab[word] = cnt_word\n",
        "        cnt_word += 1\n",
        "    \n",
        "print(\"字典:\")\n",
        "cnt = 0\n",
        "for k,v in vocab.items():\n",
        "    print(f\"{k}:{v}\")\n",
        "    cnt += 1\n",
        "    if cnt > 20:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cKXhP69_6VC"
      },
      "source": [
        "#### Transition counts\n",
        "- The first dictionary is the `transition_counts` dictionary which computes the number of times each tag happened next to another tag. \n",
        "\n",
        "This dictionary will be used to compute: \n",
        "$$P(t_i |t_{i-1}) \\tag{1}$$\n",
        "\n",
        "This is the probability of a tag at position $i$ given the tag at position $i-1$.\n",
        "\n",
        "In order for you to compute equation 1, you will create a `transition_counts` dictionary where \n",
        "- The keys are `(prev_tag, tag)`\n",
        "- The values are the number of times those two tags appeared in that order. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LrLRGlhBlo_"
      },
      "source": [
        "#### Emission counts\n",
        "\n",
        "The second dictionary you will compute is the `emission_counts` dictionary. This dictionary will be used to compute:\n",
        "\n",
        "$$P(w_i|t_i)\\tag{2}$$\n",
        "\n",
        "In other words, you will use it to compute the probability of a word given its tag. \n",
        "\n",
        "In order for you to compute equation 2, you will create an `emission_counts` dictionary where \n",
        "- The keys are `(tag, word)` \n",
        "- The values are the number of times that pair showed up in your training set. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bA7drcVBrw1"
      },
      "source": [
        "#### Tag counts\n",
        "\n",
        "The last dictionary you will compute is the `tag_counts` dictionary. \n",
        "- The key is the tag \n",
        "- The value is the number of times each tag appeared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CS9dQq1v_k6d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def create_dictionaries(sentences_list, pos_list):\n",
        "    \n",
        "    # initialize the dictionaries using defaultdict\n",
        "    emission_counts = defaultdict(int)\n",
        "    transition_counts = defaultdict(int)\n",
        "    tag_counts = defaultdict(int)\n",
        "\n",
        "    sentence_len = len(sentences_list)\n",
        "    \n",
        "    # use 'i' to track the line number in the corpus\n",
        "    i = 0 \n",
        "    \n",
        "    # Each item in the training corpus contains a word and its POS tag\n",
        "    # Go through each word and its tag in the training corpus\n",
        "    for sentence_idx in range(sentence_len):\n",
        "      prev_tag = pos_list[sentence_idx][0]\n",
        "      tag_counts[prev_tag] += 1\n",
        "      for word_tag_idx in range(1, len(sentences_list[sentence_idx])):\n",
        "        \n",
        "        # Increment the word_tag count\n",
        "        i += 1\n",
        "        \n",
        "        # Every 5,000 words, print the word count\n",
        "        if i % 5000 == 0:\n",
        "            print(f\"word count = {i}\")\n",
        "\n",
        "        # get the word and tag using the get_word_tag helper function (imported from utils_pos.py)\n",
        "        word, tag = sentences_list[sentence_idx][word_tag_idx], pos_list[sentence_idx][word_tag_idx]\n",
        "        \n",
        "        # Increment the transition count for the previous word and tag\n",
        "        transition_counts[(prev_tag, tag)] += 1\n",
        "        \n",
        "        # Increment the emission count for the tag and word\n",
        "        emission_counts[(tag, word)] += 1\n",
        "\n",
        "        # Increment the tag count\n",
        "        tag_counts[tag] += 1\n",
        "\n",
        "        # Set the previous tag to this tag (for the next iteration of the loop)\n",
        "        prev_tag = tag\n",
        "        \n",
        "    return emission_counts, transition_counts, tag_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiCzVNeJHeYe",
        "outputId": "4ca07b61-1d93-46c2-8a33-c56b266887b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word count = 5000\n",
            "word count = 10000\n",
            "word count = 15000\n",
            "word count = 20000\n",
            "word count = 25000\n",
            "word count = 30000\n",
            "word count = 35000\n",
            "word count = 40000\n",
            "word count = 45000\n",
            "word count = 50000\n",
            "word count = 55000\n",
            "word count = 60000\n",
            "word count = 65000\n",
            "word count = 70000\n",
            "word count = 75000\n",
            "word count = 80000\n",
            "word count = 85000\n",
            "word count = 90000\n",
            "word count = 95000\n"
          ]
        }
      ],
      "source": [
        "emission_counts, transition_counts, tag_counts = create_dictionaries(sentences_list, pos_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqbnTwHaHnvZ",
        "outputId": "9c23169c-5b95-43b3-eccd-0bb500786f73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of POS tags (number of 'states'): 16\n",
            "View these POS tags (states)\n",
            "['--s--', 'ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SYM', 'VERB', 'X']\n"
          ]
        }
      ],
      "source": [
        "# get all the POS states\n",
        "states = sorted(tag_counts.keys())\n",
        "print(f\"Number of POS tags (number of 'states'): {len(states)}\")\n",
        "print(\"View these POS tags (states)\")\n",
        "print(states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTR1GSD-H6th",
        "outputId": "7640dc84-9aed-465c-bfdb-70237332eb1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "transition examples: \n",
            "(('--s--', 'AUX'), 8)\n",
            "(('AUX', 'ADJ'), 217)\n",
            "(('ADJ', 'PUNCT'), 464)\n",
            "\n",
            "emission examples: \n",
            "(('PUNCT', '：'), 86)\n",
            "(('PUNCT', '「'), 332)\n",
            "(('VERB', '吃'), 9)\n"
          ]
        }
      ],
      "source": [
        "print(\"transition examples: \")\n",
        "for ex in list(transition_counts.items())[:3]:\n",
        "    print(ex)\n",
        "print()\n",
        "\n",
        "print(\"emission examples: \")\n",
        "for ex in list(emission_counts.items())[200:203]:\n",
        "    print (ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV4D8i-aIENX"
      },
      "outputs": [],
      "source": [
        "def create_transition_matrix(alpha, tag_counts, transition_counts):\n",
        "\n",
        "    # Get a sorted list of unique POS tags\n",
        "    all_tags = sorted(tag_counts.keys())\n",
        "    \n",
        "    # Count the number of unique POS tags\n",
        "    num_tags = len(all_tags)\n",
        "    \n",
        "    # Initialize the transition matrix 'A'\n",
        "    A = np.zeros((num_tags, num_tags))\n",
        "    \n",
        "    # Get the unique transition tuples (previous POS, current POS)\n",
        "    trans_keys = set(transition_counts.keys())\n",
        "    \n",
        "    # Go through each row of the transition matrix A\n",
        "    for i in range(num_tags):\n",
        "        \n",
        "        # Go through each column of the transition matrix A\n",
        "        for j in range(num_tags):\n",
        "\n",
        "            # Initialize the count of the (prev POS, current POS) to zero\n",
        "            count = 0\n",
        "        \n",
        "            # Define the tuple (prev POS, current POS)\n",
        "            # Get the tag at position i and tag at position j (from the all_tags list)\n",
        "            key = (all_tags[i], all_tags[j])\n",
        "\n",
        "            # Check if the (prev POS, current POS) tuple \n",
        "            # exists in the transition counts dictionary\n",
        "            if key in transition_counts: #complete this line\n",
        "                \n",
        "                # Get count from the transition_counts dictionary \n",
        "                # for the (prev POS, current POS) tuple\n",
        "                count = transition_counts.get(key)\n",
        "                \n",
        "            # Get the count of the previous tag (index position i) from tag_counts\n",
        "            count_prev_tag = tag_counts[all_tags[i]]\n",
        "            \n",
        "            # Apply smoothing using count of the tuple, alpha, \n",
        "            # count of previous tag, alpha, and total number of tags\n",
        "            A[i,j] = (count + alpha)/(count_prev_tag + alpha*num_tags)\n",
        "    \n",
        "    return A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv6rfwzuKkKY",
        "outputId": "6ffa8478-b323-4443-e2c5-5ccfa86edd63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A at row 0, col 0: 0.000000250\n",
            "A at row 3, col 1: 0.0709\n",
            "View a subset of transition matrix A\n",
            "            ADJ       ADP       ADV  ...      NOUN       NUM      PART\n",
            "ADJ    0.024929  0.007356  0.016756  ...  0.325295  0.021251  0.346545\n",
            "ADP    0.024702  0.017424  0.034407  ...  0.234891  0.132995  0.043450\n",
            "ADV    0.070914  0.088152  0.089243  ...  0.031639  0.026402  0.001528\n",
            "AUX    0.075269  0.049601  0.037114  ...  0.194588  0.147415  0.014222\n",
            "CCONJ  0.048376  0.009387  0.015163  ...  0.393498  0.105415  0.016607\n",
            "DET    0.019213  0.010568  0.011528  ...  0.683948  0.156579  0.024977\n",
            "NOUN   0.020666  0.051185  0.048786  ...  0.228910  0.046313  0.128829\n",
            "NUM    0.006539  0.002429  0.001681  ...  0.899119  0.000934  0.014198\n",
            "PART   0.028583  0.020981  0.025948  ...  0.459760  0.043989  0.062842\n",
            "\n",
            "[9 rows x 9 columns]\n"
          ]
        }
      ],
      "source": [
        "alpha = 0.001\n",
        "A = create_transition_matrix(alpha, tag_counts, transition_counts)\n",
        "# Testing your function\n",
        "print(f\"A at row 0, col 0: {A[0,0]:.9f}\")\n",
        "print(f\"A at row 3, col 1: {A[3,1]:.4f}\")\n",
        "\n",
        "print(\"View a subset of transition matrix A\")\n",
        "A_sub = pd.DataFrame(A[1:10,1:10], index=states[1:10], columns = states[1:10] )\n",
        "print(A_sub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ7yjuVqKkmz"
      },
      "outputs": [],
      "source": [
        "def create_emission_matrix(alpha, tag_counts, emission_counts, vocab):\n",
        "    \n",
        "    # get the number of POS tag\n",
        "    num_tags = len(tag_counts)\n",
        "    \n",
        "    # Get a list of all POS tags\n",
        "    all_tags = sorted(tag_counts.keys())\n",
        "    \n",
        "    # Get the total number of unique words in the vocabulary\n",
        "    num_words = len(vocab)\n",
        "    \n",
        "    # Initialize the emission matrix B with places for\n",
        "    # tags in the rows and words in the columns\n",
        "    B = np.zeros((num_tags, num_words))\n",
        "    \n",
        "    # Get a set of all (POS, word) tuples \n",
        "    # from the keys of the emission_counts dictionary\n",
        "    emis_keys = set(list(emission_counts.keys()))\n",
        "\n",
        "    \n",
        "    # Go through each row (POS tags)\n",
        "    for i in range(num_tags): # complete this line\n",
        "        \n",
        "        # Go through each column (words)\n",
        "        for j in range(num_words): # complete this line\n",
        "\n",
        "            # Initialize the emission count for the (POS tag, word) to zero\n",
        "            count = 0\n",
        "                    \n",
        "            # Define the (POS tag, word) tuple for this row and column\n",
        "            key = (all_tags[i], vocab[j])\n",
        "\n",
        "            # check if the (POS tag, word) tuple exists as a key in emission counts\n",
        "            if key in emission_counts: # complete this line\n",
        "        \n",
        "                # Get the count of (POS tag, word) from the emission_counts d\n",
        "                count = emission_counts.get(key)\n",
        "                \n",
        "            # Get the count of the POS tag\n",
        "            count_tag = tag_counts[all_tags[i]]\n",
        "                \n",
        "            # Apply smoothing and store the smoothed value \n",
        "            # into the emission matrix B for this row and column\n",
        "            B[i,j] = (count+alpha)/(num_words*alpha + count_tag)\n",
        "\n",
        "    return B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZYXwu0yLSDQ",
        "outputId": "cb122fec-51db-4298-cd06-3ea2cfe27662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View Matrix position at row 0, column 0: 0.000000249\n",
            "View Matrix position at row 3, column 1: 0.000000217\n",
            "                 其實            決擇            出身            10\n",
            "ADV    1.956478e-03  2.173623e-07  2.173623e-07  2.173623e-07\n",
            "NOUN   3.687912e-08  3.691600e-05  3.687912e-08  3.687912e-08\n",
            "VERB   6.726482e-08  6.726482e-08  7.399802e-04  6.726482e-08\n",
            "NUM    1.861985e-07  1.861985e-07  1.861985e-07  1.303408e-02\n",
            "PUNCT  7.336427e-08  7.336427e-08  7.336427e-08  7.336427e-08\n"
          ]
        }
      ],
      "source": [
        "# creating your emission probability matrix. this takes a few minutes to run. \n",
        "B = create_emission_matrix(alpha, tag_counts, emission_counts, list(vocab))\n",
        "\n",
        "print(f\"View Matrix position at row 0, column 0: {B[0,0]:.9f}\")\n",
        "print(f\"View Matrix position at row 3, column 1: {B[3,1]:.9f}\")\n",
        "\n",
        "# Try viewing emissions for a few words in a sample dataframe\n",
        "cidx  = ['其實','決擇','出身', '10']\n",
        "\n",
        "# Get the integer ID for each word\n",
        "cols = [vocab[a] for a in cidx]\n",
        "\n",
        "# Choose POS tags to show in a sample dataframe\n",
        "rvals =['ADV','NOUN','VERB', 'NUM','PUNCT']\n",
        "\n",
        "# For each POS tag, get the row number from the 'states' list\n",
        "rows = [states.index(a) for a in rvals]\n",
        "\n",
        "# Get the emissions for the sample of words, and the sample of POS tags\n",
        "B_sub = pd.DataFrame(B[np.ix_(rows,cols)], index=rvals, columns = cidx )\n",
        "print(B_sub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqY3UkVNLU0Q"
      },
      "outputs": [],
      "source": [
        "def initialize(states, tag_counts, A, B, corpus, vocab):\n",
        "\n",
        "    # Get the total number of unique POS tags\n",
        "    num_tags = len(tag_counts)\n",
        "    \n",
        "    # Initialize best_probs matrix \n",
        "    # POS tags in the rows, number of words in the corpus as the columns\n",
        "    best_probs = np.zeros((num_tags, len(corpus)))\n",
        "    \n",
        "    # Initialize best_paths matrix\n",
        "    # POS tags in the rows, number of words in the corpus as columns\n",
        "    best_paths = np.zeros((num_tags, len(corpus)), dtype=int)\n",
        "    \n",
        "    # Define the start token\n",
        "    s_idx = states.index(\"--s--\")\n",
        "    \n",
        "    # Go through each of the POS tags\n",
        "    for i in range(num_tags): # complete this line\n",
        "        \n",
        "        # Handle the special case when the transition from start token to POS tag i is zero\n",
        "        if A[s_idx, i] == 0: # complete this line\n",
        "            \n",
        "            # Initialize best_probs at POS tag 'i', column 0, to negative infinity\n",
        "            best_probs[i,0] = float('-inf')\n",
        "        \n",
        "        # For all other cases when transition from start token to POS tag i is non-zero:\n",
        "        else:\n",
        "            \n",
        "            # Initialize best_probs at POS tag 'i', column 0\n",
        "            # Check the formula in the instructions above\n",
        "            best_probs[i,0] = math.log(A[s_idx][i]) + math.log(B[i][vocab[corpus[0]]])\n",
        "\n",
        "    return best_probs, best_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAeZQw0SMfBO",
        "outputId": "6a6ae79f-8e52-408f-9981-d4fd16a96105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best_probs[0,0]: -30.4065\n",
            "best_paths[2,3]: 0.0000\n"
          ]
        }
      ],
      "source": [
        "best_probs, best_paths = initialize(states, tag_counts, A, B, sentences_list[0], vocab)\n",
        "# Test the function\n",
        "print(f\"best_probs[0,0]: {best_probs[0,0]:.4f}\")\n",
        "print(f\"best_paths[2,3]: {best_paths[2,3]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ubgVlKxMkuL"
      },
      "outputs": [],
      "source": [
        "def viterbi_forward(A, B, test_corpus, best_probs, best_paths, vocab):\n",
        "    # Get the number of unique POS tags (which is the num of rows in best_probs)\n",
        "    num_tags = best_probs.shape[0]\n",
        "    \n",
        "    # Go through every word in the corpus starting from word 1\n",
        "    # Recall that word 0 was initialized in `initialize()`\n",
        "    for i in range(1, len(test_corpus)): \n",
        "        \n",
        "        # Print number of words processed, every 5000 words\n",
        "        if i % 5000 == 0:\n",
        "            print(\"Words processed: {:>8}\".format(i))\n",
        "            \n",
        "        ### START CODE HERE (Replace instances of 'None' with your code EXCEPT the first 'best_path_i = None') ###\n",
        "        # For each unique POS tag that the current word can be\n",
        "        for j in range(num_tags): # complete this line\n",
        "            \n",
        "            # Initialize best_prob for word i to negative infinity\n",
        "            best_prob_i = float('-inf')\n",
        "            \n",
        "            # Initialize best_path for current word i to None\n",
        "            best_path_i = None\n",
        "\n",
        "            # For each POS tag that the previous word can be:\n",
        "            for k in range(num_tags): # complete this line\n",
        "            \n",
        "                # Calculate the probability = \n",
        "                # best probs of POS tag k, previous word i-1 + \n",
        "                # log(prob of transition from POS k to POS j) + \n",
        "                # log(prob that emission of POS j is word i)\n",
        "                prob = best_probs[k][i-1] + math.log(A[k][j]) + math.log(B[j][vocab[test_corpus[i]]]) \n",
        "\n",
        "                # check if this path's probability is greater than\n",
        "                # the best probability up to and before this point\n",
        "                if best_prob_i < prob: # complete this line\n",
        "                    \n",
        "                    # Keep track of the best probability\n",
        "                    best_prob_i = prob\n",
        "                    \n",
        "                    # keep track of the POS tag of the previous word\n",
        "                    # that is part of the best path.  \n",
        "                    # Save the index (integer) associated with \n",
        "                    # that previous word's POS tag\n",
        "                    best_path_i = k\n",
        "\n",
        "            # Save the best probability for the \n",
        "            # given current word's POS tag\n",
        "            # and the position of the current word inside the corpus\n",
        "            best_probs[j,i] = best_prob_i\n",
        "            \n",
        "            # Save the unique integer ID of the previous POS tag\n",
        "            # into best_paths matrix, for the POS tag of the current word\n",
        "            # and the position of the current word inside the corpus.\n",
        "            best_paths[j,i] = best_path_i\n",
        "\n",
        "        ### END CODE HERE ###\n",
        "    return best_probs, best_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hT6O4liidkR"
      },
      "outputs": [],
      "source": [
        "# this will take a few minutes to run => processes ~ 30,000 words\n",
        "best_probs, best_paths = viterbi_forward(A, B, sentences_list[0], best_probs, best_paths, vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BvOG0kgiguU",
        "outputId": "38808c7c-57a9-48d9-c319-724378b7beff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best_probs[0,1]: -45.7716\n",
            "best_probs[0,4]: -69.5671\n"
          ]
        }
      ],
      "source": [
        "# Test this function \n",
        "print(f\"best_probs[0,1]: {best_probs[0,1]:.4f}\") \n",
        "print(f\"best_probs[0,4]: {best_probs[0,4]:.4f}\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JSSY5yfim0J"
      },
      "outputs": [],
      "source": [
        "def viterbi_backward(best_probs, best_paths, corpus, states):\n",
        "    '''\n",
        "    This function returns the best path.\n",
        "    \n",
        "    '''\n",
        "    # Get the number of words in the corpus\n",
        "    # which is also the number of columns in best_probs, best_paths\n",
        "    m = best_paths.shape[1] \n",
        "    \n",
        "    # Initialize array z, same length as the corpus\n",
        "    z = [None] * m\n",
        "    \n",
        "    # Get the number of unique POS tags\n",
        "    num_tags = best_probs.shape[0]\n",
        "    \n",
        "    # Initialize the best probability for the last word\n",
        "    best_prob_for_last_word = float('-inf')\n",
        "    \n",
        "    # Initialize pred array, same length as corpus\n",
        "    pred = [None] * m\n",
        "    \n",
        "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "    ## Step 1 ##\n",
        "    \n",
        "    # Go through each POS tag for the last word (last column of best_probs)\n",
        "    # in order to find the row (POS tag integer ID) \n",
        "    # with highest probability for the last word\n",
        "    for k in range(num_tags): # complete this line\n",
        "\n",
        "        # If the probability of POS tag at row k \n",
        "        # is better than the previously best probability for the last word:\n",
        "        if best_probs[k][m-1] > best_prob_for_last_word: # complete this line\n",
        "            \n",
        "            # Store the new best probability for the last word\n",
        "            best_prob_for_last_word = best_probs[k][m-1]\n",
        "    \n",
        "            # Store the unique integer ID of the POS tag\n",
        "            # which is also the row number in best_probs\n",
        "            z[m - 1] = k\n",
        "            \n",
        "    # Convert the last word's predicted POS tag\n",
        "    # from its unique integer ID into the string representation\n",
        "    # using the 'states' list\n",
        "    # store this in the 'pred' array for the last word\n",
        "    pred[m - 1] = states[z[m - 1]]\n",
        "    \n",
        "    ## Step 2 ##\n",
        "    # Find the best POS tags by walking backward through the best_paths\n",
        "    # From the last word in the corpus to the 0th word in the corpus\n",
        "    for i in range(m - 1, -1, -1): # complete this line\n",
        "        \n",
        "        # Retrieve the unique integer ID of\n",
        "        # the POS tag for the word at position 'i' in the corpus\n",
        "        pos_tag_for_word_i = z[i]\n",
        "        \n",
        "        # In best_paths, go to the row representing the POS tag of word i\n",
        "        # and the column representing the word's position in the corpus\n",
        "        # to retrieve the predicted POS for the word at position i-1 in the corpus\n",
        "        z[i - 1] = best_paths[pos_tag_for_word_i][i]\n",
        "        \n",
        "        # Get the previous word's POS tag in string form\n",
        "        # Use the 'states' list, \n",
        "        # where the key is the unique integer ID of the POS tag,\n",
        "        # and the value is the string representation of that POS tag\n",
        "        pred[i - 1] = states[z[i-1]]\n",
        "        \n",
        "     ### END CODE HERE ###\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3ycN2gFiplq",
        "outputId": "942cbfe9-e699-425b-bec9-f0c0cb7da6d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The prediction for pred[-7:m-1] is: \n",
            " ['，', '最後', '決定', '的', '還是', '自己'] \n",
            " ['PUNCT', 'NOUN', 'VERB', 'PART', 'CCONJ', 'PRON'] \n",
            "\n",
            "The prediction for pred[0:8] is: \n",
            " ['PRON', 'AUX', 'ADJ', 'PUNCT', 'ADV', 'AUX', 'NUM'] \n",
            " ['--s--', '看似', '簡單', '，', '只', '是', '二']\n",
            "pos:  ['--s--', 'AUX', 'ADJ', 'PUNCT', 'ADV', 'VERB', 'NUM']\n"
          ]
        }
      ],
      "source": [
        "# Run and test your function\n",
        "pred = viterbi_backward(best_probs, best_paths, sentences_list[0], states)\n",
        "m=len(pred)\n",
        "print('The prediction for pred[-7:m-1] is: \\n', sentences_list[0][-7:m-1], \"\\n\", pred[-7:m-1], \"\\n\")\n",
        "print('The prediction for pred[0:8] is: \\n', pred[0:7], \"\\n\", sentences_list[0][0:7])\n",
        "print('pos: ', pos_list[0][0:7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLUphCLYirN3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Hmm_vertbi.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
